{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不能用测试数据去训练模型，不到最后一步不能用\n",
    "### 机器学习主要算法\n",
    "* Decision Tree 决策树 (软件推荐)\n",
    "* Naive Bayes Algorithm 朴素贝叶斯 (识别垃圾邮件)\n",
    "* Gradient descent 梯度下降 (下山问题)  \n",
    " Gradient descent to minimize the error    \n",
    "* Linear Regression 线性回归 (预测房价)  \n",
    "* Logistic Regression 逻辑回归 (预测学生是否录取)   cut in half ,based on the labels\n",
    "* Vetcor Machine 支持向量机   Maximize distance()  carefully look the boundary, make the cut based on those\n",
    "* Neural Network 神经网络 **like a team of LR.VM**  cut into regions based on the labes\n",
    "* Kernel Trick 核方法   It`s very well used in support vector machines.  (如：利用三维区分)\n",
    "* K-Means Clustering K均值聚类(披萨店位置选择)\n",
    "* Hierarchial Clustering  层次聚类 (聚类数目位置)\n",
    "\n",
    "## 一、机器学习基础\n",
    "### 1.培训与测试模型\n",
    "数学基础：\n",
    "* 中位数\n",
    "    * 样本总数为奇数时，中位数为第(n+1)/2个值；\n",
    "    * 样本总数为偶数时，中位数是第n/2个，第(n/2)+1个值的平均数；\n",
    "* 四分位数： “中位数”，把样本分成了2部分，再找个这2部分各自的“中位数”，也就把样本分为了4个部分，其中1/4处的值记为Q1，2/4处的值记为Q2，3/4处的值记为Q3\n",
    "* 四分位距 IQR=Q3-Q1\n",
    "* 异常值 小于Q1-1.5(IQR)或者大于Q3+1.5(IQR); 对于异常值，我们在处理时需要剔除；\n",
    "* 贝塞尔矫正：修正样本方差  实际在计算方差时，分母要用**n-1**，而不是样本数量n\n",
    "\n",
    "#### Pandas \n",
    "> 打开数据集： \n",
    "\n",
    "   `data = pandas.read_csv(\"2_class_data.csv\")`\n",
    "\n",
    "#### Numpy\n",
    "pandas 数据框 data, 提取A,B列 `data[['A', 'B']]`, 转变为Numpy数组，`numpy.array(data[['A', 'B']])`\n",
    "\n",
    "#### 在 scikit learn 中训练模型\n",
    "* 定义分类器，然后使用下面这行代码使分类器与数据拟合（称为 X, y）：  \n",
    "`classifier.fit(X,y)`\n",
    "\n",
    "以下是我们定义的主分类器，以及必须导入的文件包：\n",
    "\n",
    "* 逻辑回归\n",
    "```\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "```\n",
    "* 神经网络\n",
    "（注意：仅适用于 0.18 或更高版本的 scikit-learn）\n",
    "```\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier()\n",
    "```\n",
    "* 决策树\n",
    "```\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier()\n",
    "```\n",
    "* 支持向量机\n",
    "   * kernel: linear (线性)， poly（多项式）, rbf（高斯核）\n",
    "   * degree（整型）：多项式内核的次数（如果选择了多项式内核）\n",
    "   *　gamma （浮点型）：γ 参数\n",
    "   * C（浮点型）：C 参数\n",
    "```\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "```  \n",
    "#### 测试你的模型\n",
    "\n",
    "一般形式：\n",
    "train_test_split是交叉验证中常用的函数，功能是从样本中随机的按比例选取train data和testdata，形式为：\n",
    "\n",
    "X_train,X_test, y_train, y_test =\n",
    "\n",
    "cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)\n",
    "\n",
    "参数解释：\n",
    "* train_data：所要划分的样本特征集\n",
    "\n",
    "* train_target：所要划分的样本结果\n",
    "\n",
    "* test_size：样本占比，如果是整数的话就是样本的数量\n",
    "\n",
    "* random_state：是随机数的种子。\n",
    "\n",
    "随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。\n",
    "\n",
    "随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则：\n",
    "\n",
    "种子不同，产生不同的随机数；种子相同，即使实例不同也产生相同的随机数。\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "```  \n",
    "  **shalt never use testing data for training**  \n",
    "find a model that generalizes(泛化能力) well  \n",
    "* training set     to train the model \n",
    "* testing set      test the results\n",
    "```\n",
    "X_tain, X_test, y_tarin, y_test =\n",
    "train_test_split(X,\n",
    "                y,\n",
    "                test_size = 0.25)   # 25% for test and 75% for train\n",
    "```\n",
    "### 2.评估指标\n",
    "#### 混淆矩阵\n",
    " * True Positives  有说有     真正例\n",
    " * False Negatives 没有说有   假负例\n",
    " * False Positives 有说没有   假正例\n",
    " * True Negatives  没有说没有  真负例\n",
    "#### 准确率\n",
    "   Accuracy = Correctly classified points / All Points\n",
    "\n",
    "> Medical Model     High Recall 高召回率 　：False Positives is OK  \n",
    "> Spam Detector     High Precision 高精度　：False Negatives is OK\n",
    "#### Precision\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "#### Recall \n",
    "Recall = True Positives / ( True Positives + False Negatives)\n",
    "#### F1 得分\n",
    "Arithmetic Mean = (x+y)/2  \n",
    "Harmonic Mean = 2xy/(x+y) 调和平均数 始终 小于等于 算数平均数  越大越好， \n",
    "F<sub>1</sub>Score = Harmonic Mean(Precision, Recall)  \n",
    "#### F<sub>β </sub>\n",
    " β 越小越偏向精度。β =0 得出精度，β 无穷大，得出召回率   \n",
    " ![](https://github.com/hekuang/Machine-Learning_udacity/blob/master/Snipaste_2018-05-09_20-32-32.png)  \n",
    "\n",
    "#### ROC 曲线(Receiver Operating Characteristic) \n",
    "* True Positive Rate = (True Positives) / (All Positives)  \n",
    "* False Positive Rate = (False Positives)/(All Positives)  \n",
    "( False Positive Rate,True Positive Rate )z作为坐标，围绕正xy轴，做图，计算面积\n",
    "#### 回归指标\n",
    "* Mean Absolute Error 平均绝对误差\n",
    "* Mean Squared Error 均方误差\n",
    "* Regression metric 回归度量\n",
    "   * R2 Score 1-(均方误差/简单模型的均方差）所以越接近1越好，代表均方差小\n",
    "\n",
    "### 3.模型选择\n",
    "> underfitting 欠拟合 高偏差\n",
    "> overfitting 过拟合  高方差误差  Degree（次）\n",
    "#### Cross Validation\n",
    "* Training Errors　训练出错点\n",
    "*　Testing Errors  测试出错点\n",
    "增加Cross Validation(交叉验证集)\n",
    "\n",
    "#### K_Fold  Cross  Validation (K折交叉验证)\n",
    "1.数据分为K个包\n",
    "2.Training K次，每次选其中一个包来testing\n",
    "3.取平均值来得到模型  \n",
    "防止使用测试数据进行训练带来的**过拟合**\n",
    "```\n",
    "from sklean.model_selection import KFold\n",
    "kf = KFold(a,b,shuffle = True) \n",
    "# a is the size of the data, b is the size of the testing set\n",
    "# shuffle = True 代表随机选择testing 数据\n",
    "\n",
    "```\n",
    "\n",
    "#### Learning Curves 学习曲线\n",
    "![学习曲线](https://github.com/hekuang/Machine-Learning_udacity/blob/master/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF.png)  \n",
    "**过拟合： 训练得分高，测试得分低，记住了测试数据，无法泛化**  \n",
    "欠拟合： 都低  \n",
    "\n",
    "#### 网格搜索\n",
    "> 都选择F1 得分高的 Hyperparameter 超参数\n",
    "* 逻辑回归 logisitc regression  \n",
    "    Hyperparameters    Degree （次）\n",
    "* 决策树 Decision Tree\n",
    "    Hyperparameters is  depth(深度)\n",
    "* 支持向量机 Support Vector Machine\n",
    "   Hyperparameters is kernel(内核) and γ \n",
    "   用指数增加的γ(如：0.1， 1 ， 10 ，100....)来训练不同线性和多项式\n",
    "\n",
    "####　\n",
    "* 数据 Data\n",
    "* 算法 Alforithms\n",
    "* 指标 Metrics\n",
    "   * 模型复杂度表 Modle complexity graphs\n",
    "   * 精度 accuracy  \n",
    "   * 召回率 recall\n",
    "   * F1   Fβ \n",
    "   * 学习曲线 learning curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
